{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Assignment 4 - Computer Vision (CSc8830) </h1>\n",
    "<h3> Instructor: Dr. Ashwin Ashok - Spring 2024 </h3>\n",
    "<h3> Student name: Reza Mansouri </h3>\n",
    "<h4> Repository address: https://github.com/rezmansouri/csc8830/tree/main/Assignment%204"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1\n",
    "<h4>Implement an application (must run on web or as an app on mobile device) using the stereo camera where it will recognize, track and estimate dimensions (at least 2D) of any object within 3m distance and inside field-of-view to the camera. You can use barcodes or text recognition tools for identification. However, the entire object must be tracked (not just the barcode or text). Machine/Deep learning tools are NOT allowed.\n",
    "</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I implemented the recognition and tracking part by feature matching. Please find the attached screen recording and the code in the attachments. Here's also the code and some footage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "object_1 = plt.imread('input/book.jpg')\n",
    "object_2 = plt.imread('input/cream.jpg')\n",
    "object_3 = plt.imread('input/bowl.jpg')\n",
    "\n",
    "label_1 = 'Book'\n",
    "label_2 = 'Cream'\n",
    "label_3 = 'Bowl'\n",
    "\n",
    "cv2.namedWindow(\"Reza Mansouri - A4Q1\", cv2.WINDOW_FREERATIO)\n",
    "vc = cv2.VideoCapture(0)\n",
    "vc.set(cv2.CAP_PROP_FRAME_WIDTH, 360)\n",
    "vc.set(cv2.CAP_PROP_FRAME_HEIGHT, 200) \n",
    "\n",
    "if vc.isOpened():\n",
    "    rval, frame = vc.read()\n",
    "else:\n",
    "    rval = False\n",
    "\n",
    "while rval:\n",
    "    ssds = []\n",
    "    coords = []\n",
    "    for i in range(0, frame.shape[0] - object_1.shape[0], 30):\n",
    "        for j in range(0, frame.shape[1] - object_1.shape[1], 30):\n",
    "            candidate = frame[i:i+object_1.shape[0], j:j+object_1.shape[1]]\n",
    "            ssd = np.sum(np.power(candidate-object_1, 2))\n",
    "            ssds.append(ssd)\n",
    "            coords.append((j, i))\n",
    "    min_ix = np.argmin(ssds)\n",
    "    ssd = ssds[min_ix]\n",
    "    if ssd < np.mean(ssds[~min_ix]) * .95:\n",
    "        left_top = coords[min_ix]\n",
    "        right_bottom = (left_top[0] + object_1.shape[1], left_top[1] + object_1.shape[0])\n",
    "        frame = cv2.rectangle(frame, left_top, right_bottom, color=(0, 255, 255), thickness=5)\n",
    "        frame = cv2.putText(frame, label_1, (left_top[0], left_top[1]-10), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 0), 2)\n",
    "    else:\n",
    "        ssds = []\n",
    "        coords = []\n",
    "        for i in range(0, frame.shape[0] - object_2.shape[0], 30):\n",
    "            for j in range(0, frame.shape[1] - object_2.shape[1], 30):\n",
    "                candidate = frame[i:i+object_2.shape[0], j:j+object_2.shape[1]]\n",
    "                ssd = np.sum(np.power(candidate-object_2, 2))\n",
    "                ssds.append(ssd)\n",
    "                coords.append((j, i))\n",
    "        min_ix = np.argmin(ssds)\n",
    "        ssd = ssds[min_ix]\n",
    "        if ssd < np.mean(ssds[~min_ix]) * .94:\n",
    "            left_top = coords[min_ix]\n",
    "            right_bottom = (left_top[0] + object_2.shape[1], left_top[1] + object_2.shape[0])\n",
    "            frame = cv2.rectangle(frame, left_top, right_bottom, color=(255, 100, 0), thickness=5)\n",
    "            frame = cv2.putText(frame, label_2, (left_top[0], left_top[1]-10), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 0), 2)\n",
    "        else:\n",
    "            ssds = []\n",
    "            coords = []\n",
    "            for i in range(0, frame.shape[0] - object_3.shape[0], 30):\n",
    "                for j in range(0, frame.shape[1] - object_3.shape[1], 30):\n",
    "                    candidate = frame[i:i+object_3.shape[0], j:j+object_3.shape[1]]\n",
    "                    ssd = np.sum(np.power(candidate-object_3, 2))\n",
    "                    ssds.append(ssd)\n",
    "                    coords.append((j, i))\n",
    "            min_ix = np.argmin(ssds)\n",
    "            ssd = ssds[min_ix]\n",
    "            if ssd < np.mean(ssds[~min_ix]) * .98:\n",
    "                left_top = coords[min_ix]\n",
    "                right_bottom = (left_top[0] + object_3.shape[1], left_top[1] + object_3.shape[0])\n",
    "                frame = cv2.rectangle(frame, left_top, right_bottom, color=(0, 0, 255), thickness=5)\n",
    "                frame = cv2.putText(frame, label_3, (left_top[0], left_top[1]-10), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 0), 2)\n",
    "    cv2.imshow(\"Reza Mansouri - A4Q1\", frame)\n",
    "    rval, frame = vc.read()\n",
    "    key = cv2.waitKey(100)\n",
    "    if key == 27:\n",
    "        break\n",
    "\n",
    "vc.release()\n",
    "cv2.destroyWindow(\"Reza Mansouri - A4Q1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2\n",
    "<h4>Use the DepthAI SDK or use ORB3-Visual SLAM (https://github.com/UZ-SLAMLab/ORB_SLAM3) to execute the scripts on your depth camera and run experiments in two different locations. Provide snapshots of your SLAM output and what limitations/corner cases do you observe.\n",
    "</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I used the depthai-slam repository: https://github.com/bharath5673/depthai-slam\n",
    "\n",
    "The screen recordings have been uploaded and here is some footage:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://raw.githubusercontent.com/rezmansouri/csc8830/main/Assignment%204/figures/2-1.png\" alt=\"fig\" width=\"800\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://raw.githubusercontent.com/rezmansouri/csc8830/main/Assignment%204/figures/2-2.png\" alt=\"fig\" width=\"800\"/>"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
